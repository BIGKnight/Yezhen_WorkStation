{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from bootstrap import *\n",
    "\n",
    "def main():\n",
    "    args, logger = parsing()\n",
    "    encoder_parameters, classifier_parameters = [], []\n",
    "    logger.info('==> Building model..')\n",
    "    net = get_model(\n",
    "        args.model_name, \n",
    "        num_cls=args.num_cls, \n",
    "        adapted_dim=args.adapted_dim, \n",
    "        channels=args.channels,\n",
    "        vib=args.vib,\n",
    "        frozen=args.frozen\n",
    "    )\n",
    "\n",
    "    if args.load_path:\n",
    "        logger.info('==> Loading model..')\n",
    "        net.load_state_dict(torch.load(args.load_path))\n",
    "        \n",
    "    logger.info('==> Preparing datasets..')\n",
    "    datasets = prepare_datasets(args)\n",
    "    loaders = prepare_loaders(args, datasets)\n",
    "\n",
    "    logger.info('==> Creating pretext tasks.')\n",
    "    sstasks = parse_tasks(args, net, datasets['source']['train'], datasets['target']['unlabeled'])\n",
    "\n",
    "    if len(sstasks) == 0:\n",
    "        logger.info('==> No pretext task.')\n",
    "    else:\n",
    "        for sstask in sstasks:\n",
    "            logger.info('==> Created pretext task: {}'.format(sstask.name))\n",
    "\n",
    "    logger.info('==> Creating Optimizer & Building modules...')\n",
    "    optimizers = {}\n",
    "    params_lr = {}\n",
    "    encoder_parameters, classifier_parameters = net.get_parameters()\n",
    "    all_parameters = encoder_parameters + classifier_parameters\n",
    "    modules = building_modules(args, net, optimizers, all_parameters, params_lr, logger)\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder_parameters, lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "    classifier_optimizer = optim.SGD(classifier_parameters, lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "    main_optimizer = optim.SGD(all_parameters, lr=args.lr, momentum=0.9, weight_decay=5e-4)\n",
    "    optimizers['main'] = main_optimizer\n",
    "    optimizers['encoder'] = encoder_optimizer\n",
    "    optimizers['classifier'] = classifier_optimizer\n",
    "    params_lr['main'] = []\n",
    "    params_lr['encoder'] = []\n",
    "    params_lr['classifier'] = []\n",
    "    \n",
    "    for param_group in main_optimizer.param_groups:\n",
    "        params_lr['main'].append(param_group[\"lr\"])\n",
    "    for param_group in encoder_optimizer.param_groups:\n",
    "        params_lr['encoder'].append(param_group[\"lr\"])\n",
    "    for param_group in classifier_optimizer.param_groups:\n",
    "        params_lr['classifier'].append(param_group[\"lr\"])\n",
    "    \n",
    "    all_epoch_stats = []\n",
    "    best_tgt_te_err = 100\n",
    "    logger.info('==> Running..')\n",
    "    for epoch in range(1, args.nepoch + 1):\n",
    "        logger.info(\n",
    "            'Source epoch %d/%d main_lr=%.6f' % (\n",
    "                epoch, \n",
    "                args.nepoch, main_optimizer.param_groups[0]['lr']\n",
    "            )\n",
    "        )\n",
    "        tg_te_err = train(\n",
    "            args, \n",
    "            epoch,\n",
    "            sstasks, \n",
    "            optimizers,\n",
    "            loaders,\n",
    "            logger,\n",
    "            modules,\n",
    "            params_lr\n",
    "        )\n",
    "        if epoch % 10 == 0 and args.moco_finetune == False:\n",
    "            torch.save(net.state_dict(), args.outf + '/net_epoch_{}.pth'.format(str(epoch)))\n",
    "    #     if tg_te_err < best_tgt_te_err:\n",
    "    #         best_tgt_te_err = tg_te_err\n",
    "    #         torch.save(net.state_dict(), args.outf + '/net_epoch_{}.pth'.format(str(epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------- Options ---------------\n",
      "                        K: 256                           \n",
      "              adapted_dim: 1024                          \n",
      "              adj_lr_func: none                          \n",
      "                annealing: none                          \n",
      "               batch_size: 4                             \n",
      "                 channels: 3                             \n",
      "              contrastive: False                         \n",
      "                   cosine: False                         \n",
      "                data_root: /nfs/volume-92-5/wangyezhen_i/Datasets/CityCam\n",
      "                  dataset: citycam                       \n",
      "        domain_shift_type: convention                    \n",
      "                  dropout: False                         \n",
      "                     flip: False                         \n",
      "                   frozen: []                            \n",
      "                      gpu: [0]                           \n",
      "               image_size: 512                           \n",
      "               lambda_irm: 0.0                           \n",
      "                     lirr: False                         \n",
      "                load_path: None                          \n",
      "                     logf: /nfs/volume-92-5/wangyezhen_i/Projects/Theoretical_Projects/InstaPBM-V1/output/convention/citycam/sourceonly/253_398_counting_source_only.txt\n",
      "         logger_file_name: counting_source_only          \n",
      "                       lr: 1e-06                         \n",
      "                  lr_flip: 0.1                           \n",
      "              lr_quadrant: 0.1                           \n",
      "              lr_rotation: 0.1                           \n",
      "                  lw_flip: 0.1                           \n",
      "              lw_quadrant: 0.1                           \n",
      "              lw_rotation: 0.1                           \n",
      "                        m: 0.998                         \n",
      "                   method: source_only                   \n",
      "                milestone: 1000                          \n",
      "                      mim: False                         \n",
      "                    mixup: False                         \n",
      "            moco_finetune: False                         \n",
      "               model_name: CountingNet                   \n",
      "                   nepoch: 1000                          \n",
      "                 nthreads: 8                             \n",
      "                  num_cls: 1                             \n",
      "                     outf: /nfs/volume-92-5/wangyezhen_i/CheckPoints/CLMS/253_398_visda2017_source_only\n",
      "                   quad_p: 2                             \n",
      "                 quadrant: False                         \n",
      "                 rotation: False                         \n",
      "                   source: ['253']                       \n",
      "                   target: 398                           \n",
      "                task_type: reg                           \n",
      "                     temp: 1                             \n",
      "                trade_off: 0.1                           \n",
      "                      vib: False                         \n",
      "----------------- End -------------------\n",
      "==> Building model..\n",
      "==> Preparing datasets..\n",
      "==> Creating pretext tasks.\n",
      "==> No pretext task.\n",
      "==> Creating Optimizer & Building modules...\n",
      "==> no extra module need to be constructed.\n",
      "==> Running..\n",
      "Source epoch 1/1000 main_lr=0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> begin to load ids.\n",
      "citycam source train set size: 3536\n",
      "citycam labeled target train set size: 58\n",
      "citycam unlabeled target train set size: 4105\n",
      "citycam source test set size: 3536\n",
      "citycam target test set size: 1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tgt_test_acc: 78.70 ; src_test_acc: 49.60src_cls_loss : 0.00587, tgt_cls_loss : 0.00791, transfer_loss : 0.00000, \n",
      "Source epoch 2/1000 main_lr=0.000001\n",
      "tgt_test_acc: 34.77 ; src_test_acc: 20.96src_cls_loss : 0.00064, tgt_cls_loss : 0.00093, transfer_loss : 0.00000, \n",
      "Source epoch 3/1000 main_lr=0.000001\n",
      "tgt_test_acc: 20.67 ; src_test_acc: 13.98src_cls_loss : 0.00040, tgt_cls_loss : 0.00057, transfer_loss : 0.00000, \n",
      "Source epoch 4/1000 main_lr=0.000001\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if __name__ == '__main__':\n",
    "    logf_root='/nfs/volume-92-5/wangyezhen_i/Projects/Theoretical_Projects/InstaPBM-V1/output/convention/citycam/sourceonly/'\n",
    "    sys.argv = [\n",
    "        '',\n",
    "        '--dataset', 'citycam',\n",
    "        '--domain_shift_type', 'convention',\n",
    "        '--source', '253',\n",
    "        '--target', '398',\n",
    "        '--nepoch', '1000',\n",
    "        '--model_name', 'CountingNet',\n",
    "        '--image_size', '512',\n",
    "        '--channels', '3',\n",
    "        '--num_cls', '1',\n",
    "        '--lr', '1e-6',\n",
    "        '--milestone', '1000',\n",
    "        '--data_root', '/nfs/volume-92-5/wangyezhen_i/Datasets/CityCam',\n",
    "        '--outf', '/nfs/volume-92-5/wangyezhen_i/CheckPoints/CLMS/253_398_visda2017_source_only', \n",
    "        '--logf', logf_root + '253_398_counting_source_only.txt',\n",
    "        '--batch_size', '4',\n",
    "        '--nthreads', '8',\n",
    "        '--method', 'source_only',\n",
    "        '--logger_file_name', 'counting_source_only',\n",
    "        '--task_type', 'reg',\n",
    "        '--optimizer', 'adam'\n",
    "    ]\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
